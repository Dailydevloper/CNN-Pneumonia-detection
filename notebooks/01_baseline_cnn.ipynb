{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0563738-34b7-4354-b1e3-fb1f91fd4756",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m      5\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      6\u001b[0m     preprocessing_function\u001b[38;5;241m=\u001b[39mpreprocess_input,\n\u001b[0;32m      7\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m      8\u001b[0m     zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m      9\u001b[0m     horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m val_gen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     13\u001b[0m     preprocessing_function\u001b[38;5;241m=\u001b[39mpreprocess_input\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_gen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtrain_dir\u001b[49m,\n\u001b[0;32m     18\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m     19\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     20\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m val_data \u001b[38;5;241m=\u001b[39m val_gen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     24\u001b[0m     val_dir,\n\u001b[0;32m     25\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m     26\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     27\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import os\n",
    "\n",
    "BASE_DIR = \"../data\"\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, \"train\")\n",
    "val_dir = os.path.join(BASE_DIR, \"val\")\n",
    "test_dir = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100bb829-cf4a-43bd-ae48-e8955d3f302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6551f81-5093-4c67-96b0-c55e4f2b9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(224,224,3)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2a510-6800-4425-8631-5f9134e24e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e791a58-9365-41d6-bafa-3afe047942e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_normal = len(os.listdir(os.path.join(train_dir, \"NORMAL\")))\n",
    "train_pneumonia = len(os.listdir(os.path.join(train_dir, \"PNEUMONIA\")))\n",
    "\n",
    "total = train_normal + train_pneumonia\n",
    "\n",
    "weight_normal = total / (2 * train_normal)\n",
    "weight_pneumonia = total / (2 * train_pneumonia)\n",
    "\n",
    "class_weights = {\n",
    "    0: weight_normal,\n",
    "    1: weight_pneumonia\n",
    "}\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccc93d-0cb1-4bf1-bfdf-7b25cc3d8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # Freeze\n",
    "\n",
    "model_tl = models.Sequential([\n",
    "    layers.Rescaling(255.0),  # Undo earlier scaling\n",
    "    layers.Lambda(preprocess_input),\n",
    "\n",
    "    base_model,\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_tl.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfaa587-fded-4920-b27e-a0c4e7ed9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tl = model_tl.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba317905-69a0-469f-b6d4-c843e57dbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bfff4-0306-413d-98de-0ba944deb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224,224,3))\n",
    "\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_tl = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_tl.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bae325-4e53-4650-a842-43404d738783",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tl = model_tl.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31527d99-d82f-4a0c-9e9e-9393e9c90248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model_tl.predict(test_ds)\n",
    "y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "# True labels\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"NORMAL\", \"PNEUMONIA\"],\n",
    "            yticklabels=[\"NORMAL\", \"PNEUMONIA\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Report\n",
    "print(classification_report(y_true, y_pred, target_names=[\"NORMAL\",\"PNEUMONIA\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700369c-6e5a-4f62-b412-5c1b79797135",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tl.save(\"../models/pneumonia_mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431d110-2119-4477-83f0-d862c5d8f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tl.save(\n",
    "    \"../deploy/model/pneumonia_model.keras\",\n",
    "    include_optimizer=False\n",
    ")\n",
    "\n",
    "print(\"Clean model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e7a2a-3aac-41f1-9b55-3061da5f9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Path to exact image you tested in web\n",
    "img_path = r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\NORMAL\\NORMAL2-IM-0060-0001.jpeg\"\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image = image.resize((224,224))\n",
    "\n",
    "arr = np.array(image, dtype=np.float32)\n",
    "arr = np.expand_dims(arr, axis=0)\n",
    "arr = preprocess_input(arr)\n",
    "\n",
    "pred = model_tl.predict(arr)[0][0]\n",
    "\n",
    "print(\"Notebook prediction:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed6486-18fc-49b0-8f83-dd5f062bae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Path to exact image you tested in web\n",
    "img_path = r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\PNEUMONIA\\person78_bacteria_386.jpeg\"\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image = image.resize((224,224))\n",
    "\n",
    "arr = np.array(image, dtype=np.float32)\n",
    "arr = np.expand_dims(arr, axis=0)\n",
    "arr = preprocess_input(arr)\n",
    "\n",
    "pred = model_tl.predict(arr)[0][0]\n",
    "\n",
    "print(\"Notebook prediction:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d1ce5-1ccc-4a51-ae34-f3ad552aff22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (py310)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
