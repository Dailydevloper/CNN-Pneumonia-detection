{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6887c5b-a169-435d-87a6-35370c16258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66177b0-23f5-43e8-b39a-782b06559f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: E:\\ML\\Projects\\pneumonia_detector\\data\\train\n",
      "Val: E:\\ML\\Projects\\pneumonia_detector\\data\\val\n",
      "Test: E:\\ML\\Projects\\pneumonia_detector\\data\\test\n",
      "Train folders: ['NORMAL', 'PNEUMONIA']\n",
      "Val folders: ['NORMAL', 'PNEUMONIA']\n",
      "Test folders: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = r\"E:\\ML\\Projects\\pneumonia_detector\\data\"\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, \"train\")\n",
    "val_dir   = os.path.join(BASE_DIR, \"val\")\n",
    "test_dir  = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "print(\"Train:\", train_dir)\n",
    "print(\"Val:\", val_dir)\n",
    "print(\"Test:\", test_dir)\n",
    "\n",
    "print(\"Train folders:\", os.listdir(train_dir))\n",
    "print(\"Val folders:\", os.listdir(val_dir))\n",
    "print(\"Test folders:\", os.listdir(test_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5067f18-ba80-4525-b727-0c3ca0e005db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4434 images belonging to 2 classes.\n",
      "Found 798 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Class indices: {'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_data = val_gen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eae0783-f3a6-4815-b0c9-5a114d733742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m163,968\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,081</span> (9.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,081\u001b[0m (9.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,231,809</span> (8.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,231,809\u001b[0m (8.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,272</span> (743.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m190,272\u001b[0m (743.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "# Freeze most layers\n",
    "for layer in base_model.layers[:-80]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze last layers\n",
    "for layer in base_model.layers[-80:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(224,224,3))\n",
    "\n",
    "x = base_model(inputs, training=True)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(\n",
    "    128,\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    ")(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f3c4fc-055a-48bc-9220-3bd49b6eae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0510a321-5b87-47b2-a7f4-87eb3db61abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.8083 - loss: 0.6474 - val_accuracy: 0.7669 - val_loss: 0.6148\n",
      "Epoch 2/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.9145 - loss: 0.4567 - val_accuracy: 0.7920 - val_loss: 0.6022\n",
      "Epoch 3/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 2s/step - accuracy: 0.9369 - loss: 0.3999 - val_accuracy: 0.8070 - val_loss: 0.5944\n",
      "Epoch 4/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 2s/step - accuracy: 0.9497 - loss: 0.3705 - val_accuracy: 0.8546 - val_loss: 0.5051\n",
      "Epoch 5/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.9590 - loss: 0.3414 - val_accuracy: 0.8772 - val_loss: 0.4602\n",
      "Epoch 6/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 2s/step - accuracy: 0.9569 - loss: 0.3385 - val_accuracy: 0.9373 - val_loss: 0.3729\n",
      "Epoch 7/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.9644 - loss: 0.3206 - val_accuracy: 0.9511 - val_loss: 0.3362\n",
      "Epoch 8/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.9608 - loss: 0.3276 - val_accuracy: 0.9674 - val_loss: 0.3195\n",
      "Epoch 9/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.9673 - loss: 0.3084 - val_accuracy: 0.9762 - val_loss: 0.2964\n",
      "Epoch 10/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 2s/step - accuracy: 0.9677 - loss: 0.3113 - val_accuracy: 0.9774 - val_loss: 0.2897\n",
      "Epoch 11/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 2s/step - accuracy: 0.9709 - loss: 0.3003 - val_accuracy: 0.9762 - val_loss: 0.2864\n",
      "Epoch 12/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - accuracy: 0.9743 - loss: 0.2916 - val_accuracy: 0.9737 - val_loss: 0.2869\n",
      "Epoch 13/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 2s/step - accuracy: 0.9756 - loss: 0.2810 - val_accuracy: 0.9774 - val_loss: 0.2813\n",
      "Epoch 14/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.9777 - loss: 0.2826 - val_accuracy: 0.9749 - val_loss: 0.2861\n",
      "Epoch 15/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.9754 - loss: 0.2731 - val_accuracy: 0.9712 - val_loss: 0.2863\n",
      "Epoch 16/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 2s/step - accuracy: 0.9736 - loss: 0.2797 - val_accuracy: 0.9787 - val_loss: 0.2735\n",
      "Epoch 17/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.9741 - loss: 0.2783 - val_accuracy: 0.9749 - val_loss: 0.2774\n",
      "Epoch 18/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.9822 - loss: 0.2585 - val_accuracy: 0.9774 - val_loss: 0.2719\n",
      "Epoch 19/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 2s/step - accuracy: 0.9759 - loss: 0.2686 - val_accuracy: 0.9724 - val_loss: 0.2793\n",
      "Epoch 20/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 2s/step - accuracy: 0.9808 - loss: 0.2564 - val_accuracy: 0.9699 - val_loss: 0.2808\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c93d13-9349-41ba-bd4d-1c2a8b7bff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 910ms/step - accuracy: 0.8365 - loss: 0.7052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7052453756332397, 0.8365384340286255]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda141c6-55f3-417c-bf42-012ef297947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "\n",
    "def predict_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = img.resize((224,224))\n",
    "\n",
    "    arr = np.array(img, dtype=np.float32)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    arr = preprocess_input(arr)\n",
    "\n",
    "    pred = model.predict(arr, verbose=0)[0][0]\n",
    "    return float(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cc8610-d406-412e-84bb-4e617712620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL: 0.8869919776916504\n",
      "PNEUMONIA: 0.998544454574585\n",
      "NORMAL: 0.068330779671669\n",
      "PNEUMONIA: 0.9999887943267822\n",
      "NORMAL: 0.9688714146614075\n",
      "PNEUMONIA: 0.9949080944061279\n",
      "NORMAL: 0.33069393038749695\n",
      "PNEUMONIA: 0.9999448657035828\n"
     ]
    }
   ],
   "source": [
    "print(\"NORMAL:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\NORMAL\\IM-0091-0001.jpeg\"))\n",
    "print(\"PNEUMONIA:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\PNEUMONIA\\person67_virus_126.jpeg\"))\n",
    "print(\"NORMAL:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\NORMAL\\IM-0061-0001.jpeg\"))\n",
    "print(\"PNEUMONIA:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\PNEUMONIA\\person47_virus_99.jpeg\"))\n",
    "print(\"NORMAL:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\NORMAL\\NORMAL2-IM-0066-0001.jpeg\"))\n",
    "print(\"PNEUMONIA:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\PNEUMONIA\\person83_bacteria_407.jpeg\"))\n",
    "print(\"NORMAL:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\NORMAL\\IM-0067-0001.jpeg\"))\n",
    "print(\"PNEUMONIA:\", predict_image(r\"E:\\ML\\Projects\\pneumonia_detector\\data\\test\\PNEUMONIA\\person78_bacteria_378.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad89a237-5820-4d47-82b6-71111d0a160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\n",
    "    \"../deploy/model/pneumonia_model.keras\",\n",
    "    include_optimizer=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9c81c-33e3-4aa1-91d5-61a52dc362e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (py310)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
